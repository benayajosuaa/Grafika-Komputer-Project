"""
BRDF Estimator
==============

Core module for BRDF parameter estimation using differentiable rendering.
Implements Cook-Torrance BRDF optimization pipeline.

Author: Benaya Josua
Date: 19 February 2026
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from pathlib import Path\nfrom typing import Dict, Tuple, Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass CookTorranceBRDF(nn.Module):\n    \"\"\"Cook-Torrance BRDF model implementation.\n    \n    Implements the physically-based Cook-Torrance BRDF:\n    f_r = k_d * (c/π) + k_s * (DFG) / (4(n·l)(n·v))\n    \n    Parameters estimated:\n    - Albedo (base color): 3D RGB vector [0, 1]\n    - Roughness (surface micro-geometry): [0, 1]\n    - Metallic (metal-like property): [0, 1]\n    \"\"\"\n    \n    def __init__(self):\n        super().__init__()\n        self.pi = np.pi\n    \n    def ggx_distribution(self, nh: torch.Tensor, roughness: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        GGX Normal Distribution Function (Trowbridge-Reitz).\n        \n        Args:\n            nh: dot(normal, half) [B, H, W, 1]\n            roughness: roughness parameter [B, 1] or scalar\n            \n        Returns:\n            D: distribution value [B, H, W, 1]\n        \"\"\"\n        a = roughness * roughness\n        a2 = a * a\n        nh2 = nh * nh\n        denom = nh2 * (a2 - 1.0) + 1.0\n        return a2 / (self.pi * torch.clamp(denom * denom, min=1e-6))\n    \n    def schlick_fresnel(self, hv: torch.Tensor, f0: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Schlick Fresnel approximation.\n        F(θ) = F0 + (1 - F0) * (1 - cos(θ))^5\n        \n        Args:\n            hv: dot(half, view) [B, H, W, 1]\n            f0: Fresnel at normal incidence [B, 3] or [3]\n            \n        Returns:\n            F: Fresnel factor [B, H, W, 3]\n        \"\"\"\n        return f0 + (1.0 - f0) * torch.pow(torch.clamp(1.0 - hv, min=0.0, max=1.0), 5.0)\n    \n    def schlick_ggx(self, nl: torch.Tensor, nv: torch.Tensor, roughness: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Schlick-GGX Geometric Attenuation Function.\n        \n        Args:\n            nl: dot(normal, light) [B, H, W, 1]\n            nv: dot(normal, view) [B, H, W, 1]\n            roughness: roughness parameter\n            \n        Returns:\n            G: geometric factor [B, H, W, 1]\n        \"\"\"\n        r = (roughness + 1.0) * (roughness + 1.0) / 8.0\n        ggx_l = nl / torch.clamp(nl * (1.0 - r) + r, min=1e-6)\n        ggx_v = nv / torch.clamp(nv * (1.0 - r) + r, min=1e-6)\n        return ggx_l * ggx_v\n    \n    def forward(self,\n                normal: torch.Tensor,\n                view_dir: torch.Tensor,\n                light_dir: torch.Tensor,\n                albedo: torch.Tensor,\n                roughness: torch.Tensor,\n                metallic: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute BRDF value (radiance) for given viewing/lighting directions.\n        \n        Args:\n            normal: surface normals [B, H, W, 3]\n            view_dir: normalized view direction [B, H, W, 3]\n            light_dir: normalized light direction [B, H, W, 3]\n            albedo: base color [B, 3]\n            roughness: roughness value [B, 1]\n            metallic: metallic factor [B, 1]\n            \n        Returns:\n            color: RGB color [B, H, W, 3] clamped to [0, 1]\n        \"\"\"\n        # Ensure proper tensor shapes\n        if albedo.dim() == 1:\n            albedo = albedo.unsqueeze(0)  # [B, 3]\n        if roughness.dim() == 0:\n            roughness = roughness.unsqueeze(0).unsqueeze(0)  # [B, 1]\n        if metallic.dim() == 0:\n            metallic = metallic.unsqueeze(0).unsqueeze(0)  # [B, 1]\n        \n        # Half vector\n        half = F.normalize(view_dir + light_dir, dim=-1)\n        \n        # Dot products\n        nh = torch.clamp(torch.sum(normal * half, dim=-1, keepdim=True), 0.0, 1.0)\n        nl = torch.clamp(torch.sum(normal * light_dir, dim=-1, keepdim=True), 0.0, 1.0)\n        nv = torch.clamp(torch.sum(normal * view_dir, dim=-1, keepdim=True), 0.0, 1.0)\n        hv = torch.clamp(torch.sum(half * view_dir, dim=-1, keepdim=True), 0.0, 1.0)\n        \n        # Fresnel: F0 depends on whether surface is metallic\n        f0 = torch.lerp(\n            torch.tensor([0.04, 0.04, 0.04], device=albedo.device, dtype=albedo.dtype),\n            albedo,\n            metallic\n        )\n        f = self.schlick_fresnel(hv, f0)\n        \n        # Normal Distribution Function\n        d = self.ggx_distribution(nh, roughness)\n        \n        # Geometric Attenuation\n        g = self.schlick_ggx(nl, nv, roughness)\n        \n        # Specular component\n        numerator = d * f * g\n        denominator = torch.clamp(4.0 * nl * nv, min=1e-6)\n        specular = numerator / denominator\n        \n        # Diffuse component (Lambertian)\n        kd = (1.0 - f) * (1.0 - metallic)\n        diffuse = albedo / self.pi\n        \n        # Combine diffuse and specular\n        color = (kd * diffuse + specular) * nl\n        \n        return torch.clamp(color, 0.0, 1.0)\n\n\nclass BRDFEstimator:\n    \"\"\"High-level BRDF estimation engine.\n    \n    Handles optimization of BRDF parameters to match target image.\n    \"\"\"\n    \n    def __init__(self,\n                 device: torch.device = None,\n                 lr: float = 0.01,\n                 max_iterations: int = 1000):\n        \"\"\"\n        Initialize BRDF estimator.\n        \n        Args:\n            device: torch device (cuda or cpu)\n            lr: learning rate\n            max_iterations: maximum optimization iterations\n        \"\"\"\n        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.lr = lr\n        self.max_iterations = max_iterations\n        \n        self.brdf = CookTorranceBRDF().to(self.device)\n        self.loss_history = []\n        \n        logger.info(f\"BRDF Estimator initialized on {self.device}\")\n    \n    def initialize_parameters(self,\n                             init_albedo: Optional[np.ndarray] = None,\n                             init_roughness: float = 0.5,\n                             init_metallic: float = 0.0) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Initialize BRDF parameters.\n        \n        Args:\n            init_albedo: initial albedo [3], default [0.5, 0.5, 0.5]\n            init_roughness: initial roughness, default 0.5\n            init_metallic: initial metallic, default 0.0\n            \n        Returns:\n            Dictionary of parameter tensors with requires_grad=True\n        \"\"\"\n        if init_albedo is None:\n            init_albedo = np.array([0.5, 0.5, 0.5])\n        \n        params = {\n            'albedo': torch.tensor(init_albedo, dtype=torch.float32,\n                                  device=self.device, requires_grad=True),\n            'roughness': torch.tensor([init_roughness], dtype=torch.float32,\n                                     device=self.device, requires_grad=True),\n            'metallic': torch.tensor([init_metallic], dtype=torch.float32,\n                                    device=self.device, requires_grad=True)\n        }\n        \n        logger.info(f\"Parameters initialized: albedo={init_albedo}, \"\n                   f\"roughness={init_roughness}, metallic={init_metallic}\")\n        return params\n    \n    def compute_loss(self,\n                    rendered: torch.Tensor,\n                    target: torch.Tensor,\n                    weights: Dict[str, float] = None) -> Tuple[torch.Tensor, Dict]:\n        \"\"\"\n        Compute multi-term loss function.\n        \n        Args:\n            rendered: rendered image [B, C, H, W]\n            target: target image [B, C, H, W]\n            weights: loss component weights\n            \n        Returns:\n            total_loss: scalar tensor\n            losses_dict: individual loss terms\n        \"\"\"\n        if weights is None:\n            weights = {'photo': 0.8, 'smooth': 0.2}\n        \n        # Photometric loss (MSE)\n        loss_photo = F.mse_loss(rendered, target)\n        \n        losses = {\n            'photometric': loss_photo.item(),\n            'total': loss_photo.item()\n        }\n        \n        return loss_photo, losses\n    \n    def clamp_parameters(self, params: Dict[str, torch.Tensor]) -> None:\n        \"\"\"\n        Clamp parameters to valid ranges.\n        \n        Args:\n            params: parameter dictionary\n        \"\"\"\n        with torch.no_grad():\n            params['albedo'].clamp_(0, 1)\n            params['roughness'].clamp_(0, 1)\n            params['metallic'].clamp_(0, 1)\n    \n    def optimize(self,\n                render_fn,\n                target_image: torch.Tensor,\n                init_params: Dict[str, torch.Tensor] = None,\n                num_iterations: Optional[int] = None,\n                callback = None) -> Dict:\n        \"\"\"\n        Run optimization loop.\n        \n        Args:\n            render_fn: function that renders image given BRDF params\n            target_image: target image [B, C, H, W]\n            init_params: initial parameters\n            num_iterations: number of iterations (default: self.max_iterations)\n            callback: optional callback function called each iteration\n            \n        Returns:\n            Dictionary with optimization results\n        \"\"\"\n        if init_params is None:\n            init_params = self.initialize_parameters()\n        \n        num_iterations = num_iterations or self.max_iterations\n        \n        # Setup optimizer\n        optimizer = torch.optim.Adam(\n            list(init_params.values()),\n            lr=self.lr\n        )\n        scheduler = torch.optim.lr_scheduler.StepLR(\n            optimizer, step_size=100, gamma=0.8\n        )\n        \n        self.loss_history = []\n        param_history = {k: [] for k in init_params.keys()}\n        \n        logger.info(f\"Starting optimization for {num_iterations} iterations\")\n        \n        for iteration in range(num_iterations):\n            optimizer.zero_grad()\n            \n            # Forward pass: render with current parameters\n            rendered = render_fn(**{k: v.detach() if not v.requires_grad else v\n                                   for k, v in init_params.items()})\n            \n            # Compute loss\n            loss, losses_dict = self.compute_loss(rendered, target_image)\n            \n            # Backward pass\n            loss.backward()\n            \n            # Update parameters\n            optimizer.step()\n            scheduler.step()\n            \n            # Clamp to valid ranges\n            self.clamp_parameters(init_params)\n            \n            # Record history\n            self.loss_history.append(loss.item())\n            for k, v in init_params.items():\n                param_history[k].append(v.detach().cpu().numpy().copy())\n            \n            # Callback\n            if callback and (iteration + 1) % 50 == 0:\n                callback(iteration, loss.item(), init_params)\n        \n        logger.info(f\"Optimization complete. Final loss: {loss.item():.6f}\")\n        \n        return {\n            'parameters': init_params,\n            'loss_history': self.loss_history,\n            'param_history': param_history,\n            'final_loss': self.loss_history[-1]\n        }\n\n\nif __name__ == '__main__':\n    # Test instantiation\n    brdf = CookTorranceBRDF()\n    estimator = BRDFEstimator()\n    print(\"✓ BRDF modules loaded successfully\")\n